
# AI Anomaly Stream â€” Realâ€‘Time Anomaly Detection Platform (SWE + Data + AI)

**AI-powered streaming platform** that ingests real-time events, applies **online anomaly detection** (Isolation Forest baseline + statistical fallback), stores both events and anomalies in a lakehouse format (Parquet), and presents a **live dashboard**. Built to demonstrate **Software Engineering** + **Data Engineering** + **Applied ML** in a single, productionâ€‘styled repo.

---

## âœ¨ Highlights
- **SWE**: FastAPI ingest service, modular code, tests, Makefile, clear runbook
- **DE**: streaming processor, Parquet lake, DuckDB analytics, Streamlit dashboard
- **AI/ML**: Isolation Forest model (joblib), online stats fallback, drift hooks
- **Portable**: Runs locally in â€œLite Modeâ€ (no Kafka). Optional Docker/Kafka in Phase 2

---

## ğŸ§± Architecture (Lite Mode)
```
[Load Generator] --HTTP--> [FastAPI Ingest] --append NDJSON--> data/events.log
                                                 |
                                                 v
                                       [Streaming Processor] --writes--> lake/events/*.parquet
                                                                        lake/anomalies/*.parquet
                                                                        |
                                                                        v
                                                                 [Streamlit Dashboard]
```
**Notes**
- Ingest accepts single or batched JSON events.
- Processor tails `data/events.log`, computes features, scores anomalies with a saved IsolationForest (`artifacts/model.joblib`) or a statistical fallback, writes Parquet.
- Dashboard uses DuckDB to query Parquet and visualize trends + recent anomalies.

---

## ğŸ§­ Quickstart (Lite Mode, no Docker)
```bash
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 1) Train a baseline model & create artifacts/
python services/training/train_isoforest.py --out artifacts

# 2) Start the ingest API (terminal A)
uvicorn services.ingest_api.app:app --host 0.0.0.0 --port 8000 --reload

# 3) Start the streaming processor (terminal B)
python services/processor/streaming_processor.py

# 4) Start the dashboard (terminal C)
streamlit run services/dashboard/streamlit_app.py

# 5) Generate events (terminal D)
python services/training/generate_events.py --rate 100 --duration 60
```
Open the dashboard URL printed by Streamlit and watch anomalies appear in near real time.

---

## ğŸ“ Repository Layout
```
anomaly-stream-ai/
  services/
    ingest_api/app.py            # FastAPI: /healthz, /events
    processor/streaming_processor.py  # tails events.log, scores anomalies, writes Parquet
    dashboard/streamlit_app.py   # DuckDB queries, charts, tables
    training/train_isoforest.py  # trains IsolationForest & saves joblib
    training/generate_events.py  # synthetic event generator (HTTP posts)
    common/schemas.py            # Pydantic models & helpers
  docker/
    docker-compose.yaml          # (Phase 2) Redpanda/Kafka + services wiring
  tests/
    test_processor_smoke.py      # minimal test: writes a line, expects parquet
  assets/                        # diagrams/screenshots
  requirements.txt
  Makefile
  README.md
  .gitignore
```

---

## ğŸ”¬ Data Schema
Each event has:
- `ts` (RFC3339 string), `user_id` (str), `metric1..3` (floats), `feature_a/b` (ints/floats), and optional tags.

Anomalies are rows with an anomaly **score**, **label** (0/1), and window timestamp.

---

## ğŸ§ª Model
Baseline = **Isolation Forest** trained on synthetic normal behavior.  
Fallback = rolling **z-score** (mean/std over window) when model missing.  
Extendable to Autoencoder/LSTM later.

---

## ğŸ“Š Dashboard Panels
- Anomaly count over time
- Top users with most anomalies
- Recent anomalies table with scores
- Global metrics (event rate, anomaly rate)

---

## ğŸ§° Make Targets
```bash
make venv         # create & install deps
make train        # train model â†’ artifacts/model.joblib
make api          # run FastAPI
make stream       # run processor
make dash         # run Streamlit
make load         # run generator
```

---

## ğŸ§ª Minimal Tests
- Processor smoke test: write a sample line to `events.log`, run a quick loop, expect at least one parquet file.

---

## ğŸ§¾ Benchmarks Template (fill after your first run)
| Metric | Target | Your Result | Notes |
|---|---:|---:|---|
| Endâ€‘toâ€‘end p95 (ingestâ†’anomaly sink) | < 2 s |  |  |
| Sustained throughput | 500 evts/s |  | CPU & I/O bound |
| False positive rate | < 2% |  | validate with labeled set |

---

## ğŸ§ª Phase 2 (Docker/Kafka)
1) Enable **Redpanda** (Kafkaâ€‘compatible) via `docker-compose.yaml`.
2) Modify processor to consume from Kafka topic `events` (Faust/Confluent Python).
3) Add Prometheus + Grafana; publish FastAPI/processor metrics (latency histograms).

---

## ğŸ§¯ Runbook (Ops)
- **Backpressure**: processor lagging? Flush interval too high? Reduce batch size or parallelize feature computation.
- **Model drift**: distribution shift? Add a job to retrain daily on last N hours and compare KSâ€‘stat/pâ€‘values; if drift detected, autoâ€‘promote new model after canary.
- **No data**: check `/healthz`, then generator; ensure `events.log` is growing.

---

## ğŸ§  AI Extensions
- LLMâ€‘based anomaly explanations (summaries for the last 50 anomalous events).  
- Feature store integration; embeddingâ€‘based detectors.  
- Online learning with partial_fit models.

---

## ğŸ“ License
MIT
